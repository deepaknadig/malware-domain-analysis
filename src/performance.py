import re
with open("splitedKeyword.txt") as f:
    content = f.readlines()
#list of delimiters in the data file
delimiters = ['\n', ' ', '/', ',', '.', ':', '!', '$', '?', '%', ';', '@', '-', '_']
words = content
#print(words)
for delimiter in delimiters:
    new_words = []
    for word in words:
        new_words += word.split(delimiter)
    words = new_words
print(words)

#kmeans algorithm
import csv
import re
import pandas as pd
#df = pd.read_csv('splitKeyword.txt')
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from sklearn.metrics import adjusted_rand_score


vectorizer = TfidfVectorizer(stop_words='english')
X = vectorizer.fit_transform(words)
print(X)

#performance evaluation
X = X.toarray()
#print(X)
from sklearn.metrics import davies_bouldin_score
kmeans = KMeans(n_clusters=3, random_state=1).fit(X)
labels = kmeans.labels_
davies_bouldin_score(X, labels)
